{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f8a72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CharDataset1/a.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/b.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/c.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/d.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/e.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/f.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/g.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/h.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/i.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/j.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/k.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/l.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/m.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/n.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/o.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/p.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/q.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/r.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/s.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/t.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/u.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/v.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/w.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/x.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/y.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/z.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/0.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/1.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/2.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/3.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/4.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/5.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/6.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/7.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/8.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n",
      "./CharDataset1/9.jpg \n",
      "\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "from math import *\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import numpy\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h',\n",
    "            'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', \n",
    "            'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
    "            'y', 'z', '0', '1', '2', '3', '4', '5',\n",
    "            '6', '7', '8', '9']\n",
    "\n",
    "def toBlackWhiteBinary(img):\n",
    "    \n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            if img[i][j] < 128:\n",
    "                img[i][j] = 0\n",
    "                \n",
    "            else:\n",
    "                img[i][j] = 255\n",
    "            \n",
    "    \n",
    "    return img\n",
    "\n",
    "def makeBinaryImages():                \n",
    "    for i in alphabet:\n",
    "        path = list(\"./CharDataset1/x.jpg\")\n",
    "        path[len(path) - 5] = str(i)\n",
    "        path = \"\".join(path)\n",
    "        print(path, \"\\n\")\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        print(type(img))\n",
    "        img = toBlackWhiteBinary(img)\n",
    "        cv2.imwrite(path, img)\n",
    "        \n",
    "def ImageToArray(img):\n",
    "    final = []\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[1])):\n",
    "            final.append(img[i][j])\n",
    "            \n",
    "    for i in range(len(final)):\n",
    "        if final[i] == 255:\n",
    "            final[i] = 1\n",
    "        else:\n",
    "            final[i] = 0\n",
    "    return final\n",
    "\n",
    "def compareImage(Original, Output):\n",
    "    mismatch = 0\n",
    "    for i in range(len(Original)):\n",
    "        if Output[i] != Original[i]:\n",
    "            mismatch += 1\n",
    "    return mismatch / len(Original)\n",
    "\n",
    "#gets all dataset 1 images\n",
    "def DataSetOfAllImages():\n",
    "    dataset = []\n",
    "    for i in alphabet:\n",
    "        path = list(\"./CharDataset1/x.jpg\")\n",
    "        path[len(path) - 5] = str(i)\n",
    "        path = \"\".join(path)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img.setflags(write = 1)\n",
    "       \n",
    "        dataset.append(ImageToArray(img))\n",
    "    return dataset\n",
    "\n",
    "def Threshold(Arr):\n",
    "    newArr = []\n",
    "    for i in Arr:\n",
    "        if i > 0.5:\n",
    "            newArr.append(1)\n",
    "        else:\n",
    "            newArr.append(0)\n",
    "    return newArr\n",
    "\n",
    "def ThresholdResultArrays(arrs):\n",
    "    newArr = []\n",
    "    for i in arrs:\n",
    "        newArr.append(Threshold(i))\n",
    "    return newArr\n",
    "\n",
    "def CountWhitePixels(img):\n",
    "    count = 0\n",
    "    for i in img:\n",
    "        if i == 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def ComputeFh(correctImage, Output):\n",
    "    TotalBlackPixels = 0\n",
    "    TotalCorrectPixels = 0\n",
    "    \n",
    "    for i in range(len(correctImage)):\n",
    "        if correctImage[i] == 1:\n",
    "            TotalBlackPixels += 1\n",
    "            if(Output[i] == 1):\n",
    "                TotalCorrectPixels += 1\n",
    "    return TotalCorrectPixels / TotalBlackPixels\n",
    "\n",
    "def ComputeFhArray(correctImages, OutputImages):\n",
    "    fhArr = []\n",
    "    for i in range(len(correctImages)):\n",
    "        fhArr.append(ComputeFh(correctImages[i], OutputImages[i]))\n",
    "    return fhArr\n",
    "\n",
    "def ComputeFfa(correctImage, Output):\n",
    "    TotalWrongPixels = 0\n",
    "    \n",
    "    for i in range(len(correctImage)):\n",
    "        if (Output[i] == 1) and (correctImage[i] != 1):\n",
    "            TotalWrongPixels += 1\n",
    "    \n",
    "    return TotalWrongPixels / CountWhitePixels(correctImage)\n",
    "\n",
    "def ComputeFfaArray(correctImages, OutputImages):\n",
    "    ffaArr = []\n",
    "    for i in range(len(correctImages)):\n",
    "        ffaArr.append(ComputeFfa(correctImages[i], OutputImages[i]))\n",
    "    return ffaArr\n",
    "\n",
    "#Images would be X\n",
    "def Perturb(images, mean, std_dev):\n",
    "    \n",
    "    NoiseCorruptedImages = []\n",
    "    \n",
    "    for i in images:\n",
    "        currentImage = i\n",
    "        \n",
    "        mean, std_dev = mean, std_dev\n",
    "\n",
    "        sample = numpy.random.normal(mean, std_dev, 25)\n",
    "\n",
    "        RandomImageIndexes = random.sample(range(0, 255), 25)\n",
    "        \n",
    "        sampleIndex = 0\n",
    "        \n",
    "        for j in RandomImageIndexes:\n",
    "            currentImage[j] += sample[sampleIndex]\n",
    "            sampleIndex += 1\n",
    "        NoiseCorruptedImages.append(currentImage)\n",
    "        \n",
    "    return ThresholdResultArrays(NoiseCorruptedImages)\n",
    "            \n",
    "    \n",
    "    \n",
    "def Model(X, y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim = 256, activation='relu'))\n",
    "    #model.add(Dense(256, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    model.fit(X, y, epochs=10, batch_size=2, verbose = True)\n",
    "    return model\n",
    "\n",
    "def MultiLayerModel(X, y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim = 256, activation='relu'))\n",
    "    model.add(Dense(256, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    model.fit(X, y, epochs=20, batch_size=2, verbose = True)\n",
    "    return model\n",
    "\n",
    "def RunAnalysis(X, Y, model, plotTitle=None):\n",
    "    \n",
    "    FhArray = ComputeFhArray(X, Y)\n",
    "    FfaArray = ComputeFfaArray(X, Y)\n",
    "    \n",
    "    \n",
    "    #print(FhArray)\n",
    "    #print(FfaArray)\n",
    "    \n",
    "    plt.scatter(FfaArray, FhArray)\n",
    "    plt.title(plotTitle)\n",
    "    plt.xlabel(\"Ffa\")\n",
    "    plt.ylabel(\"Fh\")\n",
    "    plt.show()\n",
    "    \n",
    "    return [FhArray, FfaArray]\n",
    "\n",
    "def Tabulate(FhArrays, FfaArrays):\n",
    "    #([\"Image 0\",FhStdDev0, FfaStdDev0, ..., FhStdDev0.1, FfaStdDev0.1])\n",
    "    table = []\n",
    "    for i in range(10):\n",
    "        newEntry = []\n",
    "        newEntry.append(str(i))\n",
    "        for j in range(len(FhArrays)):\n",
    "            newEntry.append(str(round(FhArrays[i][j], 2)))\n",
    "            newEntry.append(str(round(FfaArrays[i][j], 2)))\n",
    "        table.append(newEntry)\n",
    "    print(tabulate(table, headers = [\"Image\", \"Fh 0\", \"Ffa 0\", \"Fh 0.001\", \"Ffa 0.001\",\n",
    "                                     \"Fh 0.002\", \"Ffa 0.002\", \"Fh 0.003\", \"Ffa 0.003\", \n",
    "                                     \"Fh 0.005\", \"Ffa 0.005\", \"Fh 0.01\", \"Ffa 0.01\", \n",
    "                                    \"Fh 0.02\", \"Ffa 0.02\", \"Fh 0.03\", \"Ffa 0.03\", \n",
    "                                     \"Fh 0.05\", \"Ffa 0.05\", \"Fh 0.1\", \"Ffa 0.1\"]))\n",
    "    \n",
    "def FinalPlot(FhArrays, FfaArrays, Std_Devs):\n",
    "    \n",
    "    for i in range(len(FhArrays)):\n",
    "        for j in range(len(FhArrays[i])):\n",
    "            for k in Std_Devs:\n",
    "                plt.scatter(k, FhArrays[i][j], color='blue')\n",
    "                plt.scatter(k, FfaArrays[i][j], color = 'red')\n",
    "    plt.title(\"Graph of Fh and Ffa vs. Noise Standard Deviation for noise-corrupted Alphanumeric Imagery (16x16 pixels) for Autoassociative Single-Layer Perceptron\")\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(\"Gaussian Noise Level (stdev, at 10 pct xsecn)\")\n",
    "    plt.xlim([0, 0.1])\n",
    "    #plt.xticks(numpy.arange(0, 0.1, 0.001))\n",
    "    \n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel(\"Fh and Ffa\")\n",
    "    \n",
    "    plt.legend([\"Blue = Fh\", \"Red = Ffa\"])\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "def RunExperiment(X, M):\n",
    "    #print(X[1])\n",
    "    Y = ThresholdResultArrays(M.predict(X))\n",
    "    a = RunAnalysis(X, Y, M, \"Fh Vs. Ffa 0 Std. Dev\")\n",
    "    \n",
    "    \n",
    "    stdDevs = [0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "    \n",
    "    FhArrays = []\n",
    "    FfaArrays = []\n",
    "    FhArrays.append(a[0])\n",
    "    FfaArrays.append(a[1])\n",
    "    \n",
    "    for i in stdDevs:\n",
    "        NoisyImages = Perturb(X, 0, i)\n",
    "        a = RunAnalysis(NoisyImages, Y, M, \"Fh Vs. Ffa Noise with Std Dev = \" + str(i))\n",
    "        FhArrays.append(a[0])\n",
    "        FfaArrays.append(a[1])\n",
    "        \n",
    "    Tabulate(FhArrays, FfaArrays)\n",
    "    stdDevs = [0] + stdDevs\n",
    "    FinalPlot(FhArrays, FfaArrays, stdDevs)\n",
    "    \n",
    "def main():\n",
    "            \n",
    "    X = numpy.array(DataSetOfAllImages())\n",
    "    y = X\n",
    "    \n",
    "    #M = Model(X, y)\n",
    "    #RunExperiment(X, M)\n",
    "    \n",
    "    print(\"Testing Multi Layer Perceptron\")\n",
    "    \n",
    "    M = MultiLayerModel(X, y)\n",
    "    RunExperiment(X, M)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "makeBinaryImages()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453abc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c110a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116d121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
